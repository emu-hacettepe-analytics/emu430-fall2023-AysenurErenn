[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the Data Cipher project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to Data Cipher’s Project Lab.\nSUMMARY \nWe have chosen the Turkey Health Survey data from the Turkey Statistical Institute for our analysis. The Turkey Health Survey is a research project that aims to understand overall health and collect data on key health indicators to measure the development of the country. The study provides international comparisons and insights into national health needs. We selected the ???Turkey Health Survey??? data set because it covers a wide range of health-related information in Turkey, including health habits, healthcare utilization, prevalent diseases, and demographic details. As a team, we aim to analyze health patterns across different gender and age groups, identify variations in health behaviors and disease occurrence, and understand health service utilization. Our ultimate goal is to provide valuable insights for health policies and activities.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello! My name is Aysenur EREN.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Question 1\n\n\nShow the code\n# Loading necessary libraries\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(reshape2))\nsuppressPackageStartupMessages(library(rvest))\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(lubridate)\n\n# Defining the url before 2010\nurl_before_2010 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&sort=moviemeter,asc&num_votes=2500,&country_of_origin=TR&count=250\"\n\n# Defining the url years between 2010 and now\nurl_2010_2023 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&sort=moviemeter,asc&num_votes=2500,&country_of_origin=TR&count=250\"\n\n\n\n\nQuestion 2\n\n\nShow the code\ndata_1 &lt;- read_html(url_before_2010)\n\n# Scraping and cleaning movie datas before year 2010\nname_1 &lt;- data_1 |&gt; html_nodes('.ipc-title__text')\nname_1 &lt;- html_text(name_1)\nname_1 &lt;- tail(head(name_1,-1),-1)\nname_1 &lt;- str_split(name_1, \" \", n=2)\nname_1 &lt;- unlist(lapply(name_1, function(x) {x[2]}))\n\nrating_1 &lt;-data_1 |&gt; html_nodes('.ratingGroup--imdb-rating')\nrating_1 &lt;- html_text(rating_1)\nrating_1 &lt;- substr(rating_1,1,3)\nrating_1 &lt;- as.numeric(rating_1)\n\nyear_1 &lt;- data_1 |&gt; html_nodes('.dli-title-metadata-item:nth-child(1)')\nyear_1 &lt;- html_text(year_1)\nyear_1 &lt;- as.numeric(year_1)\n\nduration_1 &lt;- data_1 |&gt; html_nodes('.dli-title-metadata-item:nth-child(2)')\nduration_1 &lt;- html_text(duration_1)\nduration_1 &lt;- 60*as.numeric(substr(duration_1,1,1))+ifelse(nchar(duration_1)&gt;2,as.integer(substring(duration_1,nchar(duration_1)-2,nchar(duration_1)-1)),0)\n\nvote_1 &lt;- data_1 |&gt; html_nodes('.kRnqtn')\nvote_1 &lt;- html_text(vote_1)\nvote_1 &lt;- sub(pattern = \"Votes\", replacement = \"\", x = vote_1)\nvote_1 &lt;- sub(pattern = \",\", replacement = \"\", x = vote_1)\nvote_1 &lt;- as.numeric(vote_1)\n\n# Scraping and cleaning movie datas after year 2010\ndata_2 &lt;- read_html(url_2010_2023)\n\nname_2 &lt;- data_2 |&gt; html_nodes('.ipc-title__text')\nname_2 &lt;- html_text(name_2)\nname_2 &lt;- tail(head(name_2,-1),-1)\nname_2 &lt;- str_split(name_2, \" \", n=2)\nname_2 &lt;- unlist(lapply(name_2, function(x) {x[2]}))\n\nrating_2 &lt;- data_2 |&gt; html_nodes('.ratingGroup--imdb-rating')\nrating_2 &lt;- html_text(rating_2)\nrating_2 &lt;- substr(rating_2,1,3)\nrating_2 &lt;- as.numeric(rating_2)\n\nyear_2 &lt;- data_2 |&gt; html_nodes('.dli-title-metadata-item:nth-child(1)')\nyear_2 &lt;- html_text(year_2)\nyear_2 &lt;- as.numeric(year_2)\n\nduration_2 &lt;- data_2 |&gt; html_nodes('.dli-title-metadata-item:nth-child(2)')\nduration_2 &lt;- html_text(duration_2)\nduration_2 &lt;- 60*as.numeric(substr(duration_2,1,1))+ifelse(nchar(duration_2)&gt;2,as.integer(substring(duration_2,nchar(duration_2)-2,nchar(duration_2)-1)),0)\n\nvote_2 &lt;- data_2 |&gt; html_nodes('.kRnqtn')\nvote_2 &lt;- html_text(vote_2)\nvote_2 &lt;- sub(pattern = \"Votes\", replacement = \"\", x = vote_2)\nvote_2 &lt;- sub(pattern = \",\", replacement = \"\", x = vote_2)\nvote_2 &lt;-as.numeric(vote_2)\n\n# Combining two link's datas\nnames &lt;- c(name_1,name_2)\nratings &lt;- c(rating_1,rating_2)\nyears &lt;-c(year_1,year_2)\ndurations &lt;-c(duration_1,duration_2)\nvotes &lt;-c(vote_1,vote_2)\n\nmovies &lt;- data.frame(names,years,durations,ratings,votes)\nkable(head(movies, 10), caption = \"Movies Dataframe\")\n\n\n\nMovies Dataframe\n\n\nnames\nyears\ndurations\nratings\nvotes\n\n\n\n\nNefes: Vatan Sagolsun\n2009\n128\n8.0\n35022\n\n\nBabam ve Oglum\n2005\n108\n8.2\n91037\n\n\nMasumiyet\n1997\n110\n8.1\n19295\n\n\nKader\n2006\n103\n7.8\n16264\n\n\nUzak\n2002\n110\n7.5\n22374\n\n\nEskiya\n1996\n128\n8.1\n71704\n\n\nA.R.O.G\n2008\n127\n7.3\n44635\n\n\nSevmek Zamani\n1965\n86\n8.0\n7131\n\n\nHababam Sinifi\n1975\n87\n9.2\n42512\n\n\nÜç Maymun\n2008\n109\n7.3\n22663\n\n\n\n\n\n\n\nQuestion 3\n\n\na-)\n\n\nShow the code\n# Arrange the data frame in descending order by Rating\nmovies &lt;- movies[order(movies$ratings, decreasing = TRUE),]\n\n# Top 5 and bottom 5 movies based on user ratings\ntop5_movies &lt;- head(movies, 5)\nbottom5_movies &lt;- tail(movies, 5)\n\n# Print top and bottom movies\ncat(\"Top 5 Movies:\\n\")\n\n\nTop 5 Movies:\n\n\nShow the code\nprint(top5_movies)\n\n\n                           names years durations ratings votes\n9                 Hababam Sinifi  1975        87     9.2 42512\n261       CM101MMXI Fundamentals  2013       139     9.1 46997\n25                    Tosun Pasa  1976        90     8.9 24329\n89  Hababam Sinifi Sinifta Kaldi  1975        95     8.9 24369\n73                 Süt Kardesler  1976        80     8.8 20889\n\n\nShow the code\ncat(\"Bottom 5 Movies:\\n\")\n\n\nBottom 5 Movies:\n\n\nShow the code\nprint(bottom5_movies)\n\n\n                             names years durations ratings votes\n411                 Cumali Ceber 2  2018       100     1.2 10230\n421                          Müjde  2022       288     1.2  9920\n467              15/07 Safak Vakti  2021        95     1.2 20608\n323 Cumali Ceber: Allah Seni Alsin  2017       100     1.0 39269\n372                           Reis  2017       108     1.0 73974\n\n\nI can say the following about the films in the top 5: Like all Turkish people, I watched them all many times and I think they deserve the ratings they got. All of them are movies that have been watched over and over again for years and continue to be watched.\nI don’t have enough information to comment on the last 5 movies. There are some I’ve heard of but I haven’t watched any of them.\n\n\nb-)\nHere are my top three favorite movies from that list.\n\n\nShow the code\nmovies %&gt;% \n  filter(names == \"Ayla: The Daughter of War\" | names == \"Yedinci Kogustaki Mucize\" | names == \"Babam ve Oglum\")\n\n\n                      names years durations ratings votes\n1 Ayla: The Daughter of War  2017       125     8.3 42992\n2            Babam ve Oglum  2005       108     8.2 91037\n3  Yedinci Kogustaki Mucize  2019       132     8.2 54172\n\n\n\n\nc-)\n\n\nShow the code\n# Bar plot of Number of Movies Over the Years\n\nggplot(movies, aes(x = factor(years))) +\n  geom_bar(fill = \"orange\", color = \"black\") +\n  labs(x = \"Year\", y = \"Number of Movies\") +\n  ggtitle(\"Number of Movies Over the Years\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 6),\n        axis.text.y = element_text(size = 8),\n        plot.title = element_text(size = 12, hjust = 0.5))\n\n\n\n\n\n\n\nShow the code\n# Average Ratings of movies over the years\n\nmovies %&gt;%\n  group_by(years) %&gt;%\n  summarize(rating_averages = mean(ratings)) %&gt;%\n  ggplot(aes(years, rating_averages)) + geom_point() +\n  labs(x = \"Years\", y = \"Rating Averages\") +\n  ggtitle(\"Average Ratings of Turkish Movies Over the Years\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nPlot shows a definite downward trend in ratings over time.\n\n\nShow the code\n# Box Plots of Movie Ratings Over the Years\nmovies$years &lt;- as.factor(movies$years)\nggplot(movies, aes(x = years, y = ratings, fill = factor(years))) +\n  geom_boxplot(color = \"blue\", outlier.color = \"orange\", notch = FALSE, notchwidth = 0.5, width = 0.6) +\n  labs(x = \"Year\", y = \"Rating\") +\n  ggtitle(\"Movie Ratings Over the Years\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.text.y = element_text(size = 10),\n        plot.title = element_text(size = 12, hjust = 0.5)) +\n  scale_x_discrete(labels = function(x) substr(x, 1, 4))\n\n\n\n\n\nOver the years, ratings have declined, with the gap between film ratings widening noticeably and significantly.\n\n\nd-)\n\n\nShow the code\ncorrelation &lt;- cor(movies$votes, movies$ratings)\ncat(\"Correlation between Votes and Ratings:\", correlation, \"\\n\")\n\n\nCorrelation between Votes and Ratings: 0.1308758 \n\n\nShow the code\nggplot(movies, aes(x = votes, y = ratings, color = ratings)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"orange\", formula = y ~ x) +\n  labs(x = \"Votes\", y = \"Ratings\") +\n  ggtitle(\"Scatter Plot of Votes vs Ratings\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nThe correlation coefficient, which stands at 0.130875, is rather low. We might conclude that there is a weak linear relationship between Ratings and Votes in this instance.\n\n\ne-)\n\n\nShow the code\ncorrelation_duration_rating &lt;- cor(movies$durations, movies$ratings)\ncat(\"Correlation between Duration and Ratings:\", correlation_duration_rating, \"\\n\")\n\n\nCorrelation between Duration and Ratings: -0.03186651 \n\n\nShow the code\nggplot(movies, aes(x = durations, y = ratings, color = ratings)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE, color = \"orange\", show.legend = FALSE) +\n  labs(x = \"Durations\", y = \"Ratings\") +\n  ggtitle(\"Scatter Plot of Durations vs Ratings\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_x_log10() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nWith a correlation of 0.03186651, it is rather low. We may conclude that there is a weak linear relationship between Durations and Votes in this instance. We may conclude that there is a better correlation between Ratings and Votes when comparing Ratings with Durations and Ratings with Votes.\n\nQuestion 4\n\n\nShow the code\nurl_3 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR\"\n\ndata_3 &lt;- read_html(url_3)\n\nname_3 &lt;-html_nodes(data_3,'.ipc-title__text')\nname_3 &lt;- html_text(name_3)\nname_3 &lt;- tail(head(name_3,-1),-1)\nname_3 &lt;- str_split(name_3, \" \", n=2)\nname_3 &lt;- unlist(lapply(name_3, function(x) {x[2]}))\n\nyear_3 &lt;- html_elements(data_3,'.dli-title-metadata &gt; span:nth-child(1)')\nyear_3 &lt;- html_text(year_3)\nyear_3 &lt;- as.factor(year_3)\n\nimdb_top1000 &lt;- data.frame(names=name_3,years=year_3)\nimdb_top1000\n\n\n                       names years\n1   Yedinci Kogustaki Mucize  2019\n2                 Kis Uykusu  2014\n3      Nefes: Vatan Sagolsun  2009\n4  Ayla: The Daughter of War  2017\n5             Babam ve Oglum  2005\n6                Ahlat Agaci  2018\n7    Bir Zamanlar Anadolu'da  2011\n8                     Eskiya  1996\n9                   G.O.R.A.  2004\n10                 Vizontele  2001\n11  Her Sey Çok Güzel Olacak  1998\n\n\nShow the code\n#  Join the data frames\n\nimdb_top1000$year &lt;- as.numeric(as.character(imdb_top1000$year)) \nmerged_data &lt;- left_join(imdb_top1000,movies, by = c(\"names\", \"years\"))\nmerged_data\n\n\n                       names years year durations ratings votes\n1   Yedinci Kogustaki Mucize  2019 2019       132     8.2 54172\n2                 Kis Uykusu  2014 2014       196     8.0 54647\n3      Nefes: Vatan Sagolsun  2009 2009       128     8.0 35022\n4  Ayla: The Daughter of War  2017 2017       125     8.3 42992\n5             Babam ve Oglum  2005 2005       108     8.2 91037\n6                Ahlat Agaci  2018 2018       188     8.0 27015\n7    Bir Zamanlar Anadolu'da  2011 2011       157     7.8 49365\n8                     Eskiya  1996 1996       128     8.1 71704\n9                   G.O.R.A.  2004 2004       127     8.0 66032\n10                 Vizontele  2001 2001       110     8.0 38403\n11  Her Sey Çok Güzel Olacak  1998 1998       107     8.1 27122\n\n\nShow the code\n#  The top 11 movies from first data frame based on their rank\n\nindex_2 &lt;- order(movies$rating,decreasing = TRUE )\ntop_11 &lt;- head(index_2,11)\ntop_11 &lt;- movies[top_11[1:11],]\ntop_11\n\n\n                           names years durations ratings votes\n9                 Hababam Sinifi  1975        87     9.2 42512\n261       CM101MMXI Fundamentals  2013       139     9.1 46997\n25                    Tosun Pasa  1976        90     8.9 24329\n89  Hababam Sinifi Sinifta Kaldi  1975        95     8.9 24369\n73                 Süt Kardesler  1976        80     8.8 20889\n36              Saban Oglu Saban  1977        90     8.7 18534\n59                    Zügürt Aga  1985       101     8.7 16136\n69                 Neseli Günler  1978        95     8.7 11807\n75                   Kibar Feyzo  1978        83     8.7 17126\n132      Hababam Sinifi Uyaniyor  1976        94     8.7 20640\n95                Canim Kardesim  1973        85     8.6 10097\n\n\nIf you compare both tables, the first thing you will notice is the year of release of the movies, especially the lack of older movies in the TOP 1000 IMDB list. It’s very likely that you’re only considering movies released after a certain year.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "B.S., Industrial Engineering, Hacettepe University, Turkey, 2019 - ongoing."
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nRoketsan, Candidate Engineer 2023 - ongoing\nTurk Telekom, Part Time Corporate Pricing Intern, 2023"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nTurk Telekom, Corporate Pricing Intern, 2023\nKarsan Automotive, Technical Sales Intern, 2023\nVestel, Production Intern, 2022\nKoton, Retail Analytics Intern, 2021"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Fall 2023] EMU 430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)\nDifferences between R and Python:\n\n\n\nR: In R, indices begin at 1. Additionally, it contains special data structures that are ideal for statistical analysis, such as factors, data frames, and vectors.\nPython: Python indexes data with a base of 0. Moreover, it makes use of more conventional data structures like sets, dictionaries, and lists.\n\n\n\nR: The syntax of R is designed with statistical data analysis in mind. R code is frequently written in a way that is more functional.\nPython: Python is renowned for its readability and boasts a more versatile syntax. For code blocks, it employs indentation (whitespace).\nExample:\nIn R:\n::: {.cell}\nnums &lt;- c(16, 20, 35, 63, 78)\nmean &lt;- mean(nums)\nprint(mean)\n::: {.cell-output .cell-output-stdout} [1] 42.4 ::: :::\nIn Python:\n::: {.cell}\nnums = [16, 20, 35, 63, 78]\nmean = sum(nums) / len(nums)\nprint(mean)\n:::\n\n\n\nR: R uses specific functions and expressions for string processing.\nPython: Python provides built-in string methods and libraries for string processing.\nExample:\nIn R:\n::: {.cell}\ntext &lt;- \"Hello, World!\"\nuppercase_text &lt;- toupper(text)\n:::\nIn Python:\n::: {.cell}\ntext = \"Hello, World!\"\nuppercase_text = text.upper()\n:::"
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "(c)",
    "text": "(c)\n\nlibrary(dslabs)\ndata(\"na_example\")\n\n# Count NAs\nprint(paste(\"Total number of NAs in na_example:\", sum(is.na(na_example)), \"\\n\"))\n\n[1] \"Total number of NAs in na_example: 145 \\n\"\n\n# Replace NAs with 0\nna_example_no_na &lt;- na_example\nna_example_no_na[is.na(na_example_no_na)] &lt;- 0\n\n# Print the new data (without NAs) and count NAs in the new data\nprint(na_example_no_na)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 0 2 2 1 4 0 1 1 2 1 2 2 1 2 5 0 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 0 0 0 1 1 5 1 3 1 0 4 4 7 3 2 0 0 1 0 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 0 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 0 4 3 4 3 1 2 1 0 0 0 0 1 5 1 2 1 3 5 3 2 2 0 0 0 0 3 5 3 1 1 4\n [149] 2 4 3 3 0 2 3 2 6 0 1 1 2 2 1 3 1 1 5 0 0 2 4 0 2 5 1 4 3 3 0 4 3 1 4 1 1\n [186] 3 1 1 0 0 3 5 2 2 2 3 1 2 2 3 2 1 0 2 0 1 0 0 2 1 1 0 3 0 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 0 5 1 4 0 3 0 0 1 1 5 2 3 3 2 4 0 3 2 5 0 2 3\n [260] 4 6 2 2 2 0 2 0 2 0 3 3 2 2 4 3 1 4 2 0 2 4 0 6 2 3 1 0 2 2 0 1 1 3 2 3 3\n [297] 1 0 1 4 2 1 1 3 2 1 2 3 1 0 2 3 3 2 1 2 3 5 5 1 2 3 3 1 0 0 1 2 4 0 2 1 1\n [334] 1 3 2 1 1 3 4 0 1 2 1 1 3 3 0 1 1 3 5 3 2 3 4 1 4 3 1 0 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 0 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 0 3 3 0 2 0 1 2 1 1 4 2 1 4 4 0\n [408] 1 2 0 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 0 4 4 4 1 1 0 4\n [445] 3 0 1 3 1 3 2 4 2 2 2 3 2 1 4 3 0 1 4 3 1 3 2 0 3 0 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 0 3 2 1 1 2 0 2 2 2 3 3 1 1 2 0 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 0 1 4 1 2 4 1 3 2 0 1 1 0 2 1 1 4 2 3 3 1 5 3 1 1 2 0 1 1\n [556] 3 1 3 2 4 0 2 3 2 1 2 1 1 1 2 2 3 1 5 2 0 2 0 3 2 2 2 1 5 3 2 3 1 0 3 1 2\n [593] 2 2 1 2 2 4 0 6 1 2 0 1 1 2 2 3 0 3 2 3 3 4 2 0 2 0 4 0 1 1 2 2 3 1 1 1 3\n [630] 0 2 5 0 7 1 0 4 3 3 1 0 1 1 1 1 3 2 4 2 2 3 0 0 1 4 3 2 2 2 3 2 4 2 2 4 0\n [667] 0 0 6 3 3 1 4 4 2 1 0 1 6 0 3 3 2 1 1 6 0 1 5 1 0 2 6 2 0 4 1 3 1 2 0 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 0 1 2 2 2 2 4 5 0 0 0 4 3 3 3\n [741] 2 4 2 4 0 0 0 0 2 1 0 2 4 3 2 0 2 3 1 3 4 0 1 2 1 2 0 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 0 0 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 0 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 0 1 3 1 2 0 1 2 1 2 1 0 1 3 2 3 2 0 2 1 4 2 0 0 0 2 4 2 0 0 3\n [852] 1 0 5 5 2 2 2 0 2 1 3 1 3 2 4 2 4 0 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 0 3\n [889] 3 2 2 0 0 3 2 1 2 4 1 1 1 1 4 3 2 0 3 2 0 1 0 3 2 1 1 1 2 0 2 2 3 3 2 0 0\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 0 1 1 1 0 4 3 5 1 1 2 0 2 2 2 2 5 2 2 3 1 2 3 0\n [963] 1 2 0 0 2 0 3 1 1 2 5 3 5 1 1 4 0 2 1 3 1 1 2 4 3 3 3 0 1 1 2 2 1 1 2 2 0\n[1000] 2\n\nprint(paste(\"Total number of NAs in na_example_no_na:\", sum(is.na(na_example_no_na))))\n\n[1] \"Total number of NAs in na_example_no_na: 0\""
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "(a)",
    "text": "(a)\nI watched the video was named ‘Digging a Pit of Success for Your Organization: Embracing a R-based ecosystem in the US federal government’\nClick here for watching the video\nSUMMARY\nAn economist for a US federal agency (USAID) explains how they analyzed millions of records from health institutions in countries around the world. They evaluate data such as HIV status, HIV treatment methods, and protection indicators in the President’s Emergency Plan for AIDS Relief unit. In 2015, their teams were largely using EXCEL, but later they realized that EXCEL was not suitable for large data and went beyond the limits of Excel to be more efficient in their analysis. They turned to taking advantage of R for “We have created our own ‘pit of success’ by providing analysts with the infrastructure and support needed to make it easier to learn and work with R,” says Eknomist. At this point, he talks about the importance of key point;\n\nPackages,\nBuy in,\nCommunity\n\nFirst of all, they created packages that make things easier for everyone to access and use. He explains that they achieved the creation of these packages by first creating scripts and then creating functions.\nThe second important point is that he invites people to buy and support their analysts to learn R. Although there is a need for a learning curve at this point, he emphasizes the value of learning curve time by emphasizing that routine work will accelerate and be of better quality after giving analysts enough time to learn.\nThe last important way is to build communities, he adds. While integrating R into internal use, they created a Slack group, where they saw the importance of people asking each other questions and sharing new information within the community.\nHe finishes his speech by emphasizing that they increase the quality of work and work efficiency."
  }
]